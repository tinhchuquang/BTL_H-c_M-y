{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "def csv_dist_writer(path, data):\n",
    "    f = open(path, 'a')\n",
    "    with f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerows(data)\n",
    "\n",
    "data = [\"first_name,last_name,city\".split(\",\"),\n",
    "        \"Tyrese,Hirthe,Strackeport\".split(\",\"),\n",
    "        \"Dedric,Medhurst,Stiedemannberg\".split(\",\")\n",
    "       ]\n",
    "my_list = []\n",
    "for row in data[0:]:\n",
    "    my_list.append(row)\n",
    "path = \"Train_process.csv\"\n",
    "csv_dist_writer(path, my_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_dict_reader(file_name):\n",
    "    with open(file_name) as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        header = \"Id,Title,Body,Tags\"\n",
    "        data = []\n",
    "        data.append(header.split(\",\"))\n",
    "        for row in reader:\n",
    "            if 'c++' in row['Tags']:\n",
    "                text = row['Id']+ ',' + row['Title'] + ',' + row['Body']+ ','+ row['Tags']+\"\\n\"\n",
    "                data.append(text.split(\",\"))\n",
    "    return data\n",
    "\n",
    "def csv_dist_writer(path, data):\n",
    "    f = open(path, 'w')\n",
    "    with f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "path = \"Train_process.csv\"\n",
    "data = csv_dict_reader(\"Train.csv\")\n",
    "csv_dist_writer(path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_dict_reader(file_name):\n",
    "    with open(file_name) as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        data = []\n",
    "        for row in reader:\n",
    "            if 'asp.net' in row['Tags']:\n",
    "                text = row['Id']+ ',' + row['Title'] + ',' + row['Body']+ ','+ row['Tags']+\"\\n\"\n",
    "                data.append(text.split(\",\"))\n",
    "    return data\n",
    "\n",
    "def csv_dist_writer(path, data):\n",
    "    f = open(path, 'a')\n",
    "    with f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "path = \"Train_process.csv\"\n",
    "data = csv_dict_reader(\"Train.csv\")\n",
    "csv_dist_writer(path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b0096727edd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test_Title.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_dict_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mcsv_dist_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-b0096727edd7>\u001b[0m in \u001b[0;36mcsv_dict_reader\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m'c++'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Tags'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string \n",
    "\n",
    "def process_data(my_string):\n",
    "    accptable_characters = string.ascii_letters + \"+ ,/\"\n",
    "    e = list(filter(lambda c: c in accptable_characters, my_string))\n",
    "    string1 = ''.join(e)\n",
    "    string1 = string1.replace(\"/\",\" \")\n",
    "    string1 = string1.replace(\",\",\" \")\n",
    "    return string1\n",
    "\n",
    "def csv_dict_reader(file_name):\n",
    "    with open(file_name) as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        header = \"Id,Title,Tags\"\n",
    "        data = []\n",
    "        data.append(header.split(\",\"))\n",
    "        for row in reader:\n",
    "            if 'c++' in row['Tags']:\n",
    "                tmp = row['Title']\n",
    "                tmp = process_data(tmp)\n",
    "                text = row['Id'] + ':::::' + tmp+ ':::::c++'+\"\\n\"\n",
    "                data.append(text.split(\":::::\"))\n",
    "    return data\n",
    "\n",
    "def csv_dist_writer(path, data):\n",
    "    f = open(path, 'w')\n",
    "    with f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "path = \"Test_Title.csv\"\n",
    "data = csv_dict_reader(\"Test.csv\")\n",
    "csv_dist_writer(path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_dict_reader(file_name):\n",
    "    with open(file_name) as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        data = []\n",
    "        for row in reader:\n",
    "            if 'asp.net' in row['Tags']:\n",
    "                tmp = row['Title']\n",
    "                tmp = process_data(tmp)\n",
    "                text = row['Id']+ ':::::' + tmp +':::::asp.net'+\"\\n\"\n",
    "                data.append(text.split(\":::::\"))\n",
    "    return data\n",
    "\n",
    "def csv_dist_writer(path, data):\n",
    "    f = open(path, 'a')\n",
    "    with f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "path = \"Train_Title.csv\"\n",
    "data = csv_dict_reader(\"Train.csv\")\n",
    "csv_dist_writer(path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3149984\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def load_data(path):\n",
    "    with open(path) as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            i+= 1    \n",
    "    return i\n",
    "\n",
    "data = load_data(\"Train_Title.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = [\"The sun      is bright.\",\"The sky    is blue.\"]\n",
    "test_set = [\"The sun in the sky is bright.\",\n",
    "\"We can see the shining sun, the bright sun.\"]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',min_df = 1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_set)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "print(tfidf_matrix.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sun': 3, 'bright': 1, 'sky': 2, 'blue': 0}\n",
      "[[ 0.          0.57735027  0.57735027  0.57735027]\n",
      " [ 0.          0.4472136   0.          0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "new_term_freq_matrix = tfidf_vectorizer.transform(test_set)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "print(new_term_freq_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'sun': 3, 'bright': 1, 'sky': 2, 'blue': 0}\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_set = [\"The sun is bright.\",\"The sky is blue.\"]\n",
    "test_set = [\"The sun in the sky is bright.\",\n",
    "\"We can see the shining sun, the bright sun.\"]\n",
    "count_vectorizer = CountVectorizer(stop_words='english',lowercase=True)\n",
    "term_freq_matrix = count_vectorizer.fit_transform(train_set)\n",
    "print(\"Vocabulary:\", count_vectorizer.vocabulary_)\n",
    "print(term_freq_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.57735027  0.57735027  0.57735027]\n",
      " [ 0.          0.4472136   0.          0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer(norm=\"l2\",use_idf=True, smooth_idf=True)\n",
    "tf_idf_matrix = tfidf.fit_transform(term_freq_matrix)\n",
    "new_term_freq_matrix = count_vectorizer.transform(test_set)\n",
    "tf_idf_matrix = tfidf.transform(new_term_freq_matrix)\n",
    "print(tf_idf_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'julie': 4, 'loves': 7, 'me': 8, 'more': 9, 'than': 10, 'linda': 6, 'jane': 3, 'likes': 5, 'he': 2, 'basketball': 1, 'baseball': 0}\n",
      "[[ 0.          0.          0.          0.          0.28945906  0.\n",
      "   0.38060387  0.57891811  0.57891811  0.22479078  0.22479078]\n",
      " [ 0.          0.          0.          0.41715759  0.3172591   0.3172591\n",
      "   0.          0.3172591   0.6345182   0.24637999  0.24637999]\n",
      " [ 0.48359121  0.48359121  0.48359121  0.          0.          0.36778358\n",
      "   0.          0.          0.          0.28561676  0.28561676]]\n"
     ]
    }
   ],
   "source": [
    "mydoclist = ['Julie loves me more than Linda loves me',\n",
    "'Jane likes me more than Julie loves me',\n",
    "'He likes basketball more than baseball']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=1)\n",
    "term_freq_matrix = count_vectorizer.fit_transform(mydoclist)\n",
    "print(\"Vocabulary:\", count_vectorizer.vocabulary_)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "#tfidf.fit(term_freq_matrix)\n",
    "\n",
    "tf_idf_matrix = tfidf.fit_transform(term_freq_matrix)\n",
    "print(tf_idf_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_docs = ['He watches basketball and baseball', 'Julie likes to play basketball', 'Jane loves to play baseball']\n",
    "term_freq_matrix = count_vectorizer.fit_transform(new_docs)\n",
    "new_term_freq_matrix = tfidf.transform(term_freq_matrix)\n",
    "print(new_term_freq_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The sun      is bright.', 'The sky    is blue.', 'The sun is beatifull']\n"
     ]
    }
   ],
   "source": [
    "train_set = [\"The sun      is bright.\",\"The sky    is blue.\"]\n",
    "train_set.append(\"The sun is beatifull\")\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
